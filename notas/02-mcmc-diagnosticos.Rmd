
## Diagnósticos generales para MCMC {-}

Cuando generamos una muestra de la distribución posterior usando MCMC, sin 
importar el método (Metrópolis, Gibbs, HMC), buscamos que:

1. Los valores simulados sean representativos de la distribución posterior. Esto  implica que no deben estar influenciados por el valor inicial (arbitrario) y deben explorar todo el rango de la posterior, con suficientes retornos para evaluar cuánta masa hay en cada región.

2. Debemos tener suficientes simulaciones de tal manera que las
estimaciones sean precisas y estables.

3. Queremos tener un método eficiente para generar las simulaciones.


En la práctica intentamos cumplir lo más posible estos objetivos, pues aunque en principio los métodos MCMC garantizan que una cadena infinitamente larga logrará  una representación perfecta, siempre debemos tener un criterio para cortar la cadena y evaluar la calidad de las simulaciones. 

### Representatividad {-}

**Burn-in e iteraciones iniciales**- En primer lugar, en muchas ocasiones las condiciones iniciales de las
cadenas están en partes del espacio de parámetros que son "atípicos" en
términos de la posterior. Así que es común quitar algunas observaciones
iniciales (iteraciones de *burn-in*) para minimizar su efecto en
resúmenes posteriores. 


Por ejemplo, para el ejemplo de los cantantes, podemos
ver que las iteraciones iniciales tienen como función principal
llegar a las regiones de probabilidad posterior alta:

```{r}
log_p <- crear_log_posterior_norm(cantantes$estatura_cm, mu_0, n_0, a, b) 
log_post <- function(pars) { log_p(pars[1], pars[2]) }
set.seed(823)
metro_normal <- crear_metropolis(log_post, sigma_salto = 0.5)
sim_tbl <- metro_normal(c(mu = 162, sigma = 1), 5000) 
ggplot(sim_tbl %>% filter(iter_num < 500), aes(x = mu, y = sigma)) + geom_path(alpha = 0.5) + geom_point(aes(colour = iter_num))
```

De modo que puede ser buena idea eliminar las
primeras iteraciones. En teoría, no es necesario hacer esto si
hacemos suficientes iteraciones, pues la cadena va a terminar
en su estado estable explorando la posterior. En la práctica, y
con pocas iteraciones, puede ayudar un poco a mejorar la precisión
numérica de las cantidades que queramos calcular.

```{r, fig.width=7}
sim_g <- sim_tbl %>% pivot_longer(-iter_num, 
                                    names_to = "parametro",
                                    values_to = "valor")
todas <- ggplot(sim_g, aes(x = iter_num, y = valor)) +
  geom_line(alpha = 0.5) +
  facet_wrap(~ parametro, ncol = 1, scales = "free_y") +
  labs(subtitle = "Todas las simulaciones")
sin_burnin <- 
  sim_g %>% filter(iter_num > 200) %>% 
  ggplot(aes(x = iter_num, y = valor)) +
  geom_line(alpha = 0.5) +
  facet_wrap(~ parametro, ncol = 1, scales = "free_y") +
  labs(subtitle = "Quitando 200 de burn-in")
todas + sin_burnin
```




**Convergencia a estado límite**. Para determinar la convergencia es conveniente
realizar **más de una cadena**:  buscamos ver si realmente se ha olvidado el
estado inicial, si las distribuciones de cada cadena son consistentes unas con
otras, y revisar  que algunas cadenas no hayan quedado *atoradas* en regiones
inusuales del espacio de parámetros.

Inicializamos las cadenas con valores al azar en rangos
razonables (por ejemplo simulando de la inicial):

```{r}
set.seed(8513)
valores_iniciales  <- tibble(mu_0 = rnorm(4, 160, 20), 
                             sigma_0 = runif(4, 0, 20),
                             cadena = 1:4)
sims_tbl <- valores_iniciales %>% 
  mutate(sims = map2(mu_0, sigma_0, 
    ~ metro_normal(c(mu = .x, sigma = .y), 300) )) %>% 
  unnest(sims)

ggplot(sims_tbl, aes(x = iter_num, y = sigma, colour = factor(cadena))) +
  geom_line()
```

Y este es un ejemplo donde claramente las cadenas **no** han alcanzado
un estado estable: tienen muy distintas medias y varianzas. Por ejemplo:


```{r}
set.seed(83243)
sims_tbl <- valores_iniciales %>% 
  mutate(sims = map2(mu_0, sigma_0, 
    ~ metro_normal(c(mu = .x, sigma = .y), 20000) )) %>% 
  unnest(sims)

ggplot(sims_tbl, aes(x = iter_num, y = sigma, colour = factor(cadena))) +
  geom_line()
```

Y este resultado se ve mejor. La parte *transición* hacia las zonas
de alta probabilidad pasa antes de unas 1000 iteraciones. Podemos
hacer más simulaciones, o eliminar como *burn-in* las primiras iteraciones:

```{r, fig.width = 6}
media_g <- ggplot(sims_tbl %>% filter(iter_num > 2000),
                  aes(x = iter_num, y = mu, colour = factor(cadena))) +
  geom_line()
sigma_g <- ggplot(sims_tbl %>% filter(iter_num > 2000),
                  aes(x = iter_num, y = sigma, colour = factor(cadena))) +
  geom_line()
media_g / sigma_g
```

Las gráficas anteriores nos ayudan a determinar si elegimos un periodo de 
calentamiento adecuado o si alguna cadena está alejada del resto.

Una vez que las cadenas están en estado estable, podemos usar
**todas** las simulaciones juntas para resumir:

```{r}
head(sims_tbl)
# medias posteriores
sims_tbl %>% 
  summarise(mu = mean(mu), sigma = mean(sigma))
```





Además de realizar gráficas podemos usar la medida de convergencia $\hat{R}$. La medida $\hat{R}$ se conoce como el **factor de reducción potencial de 
escala** o *diagnóstico de convergencia de Gelman-Rubin*, esta es una estimación 
de la posible reducción en la longitud de un intervalo de confianza si las 
simulaciones continuaran infinitamente. $\hat{R}$ es aproximadamente la raíz 
cuadrada de la varianza de todas las 
cadenas juntas dividida entre la varianza dentro de cada cadena. Si $\hat{R}$ es
mucho mayor a 1 esto indica que las cadenas no se han mezclado bien. Una regla
usual es iterar hasta alcanzar un valor $\hat{R} \leq 1.1$ para todos los 
parámetros.

$$\hat{R} \approx \sqrt{\frac{\hat{V}}{W}}$$

donde $B$ es la varianza entre las cadenas, $W$ es la varianza dentro de las cadenas 

$$B = \frac{N}{M-1}\sum_m (\hat{\theta}_m - \hat{\theta})^2$$
$$W = \frac{1}{M}\sum_m \hat{\sigma}_m^2$$

Y $\hat{V}$ es una estimación del varianza de posterior de $\theta$:

$$\hat{V} = \frac{N-1}{N}W + \frac{M+1}{MN}B$$
#### Ejemplo {-}
En nuestro ejemplo anterior, tenemos
```{r}
sims_tbl %>% 
  pivot_longer(mu:sigma, names_to = "parametro", values_to = "valor") %>% 
  group_by(parametro, cadena) %>% 
  summarise(media = mean(valor), num = n(), sigma2 = var(valor)) %>% 
  summarise(N = first(num),
            M = n_distinct(cadena), 
            B = N * var(media),
            W = mean(sigma2),
            V_hat = ((N - 1) / N) * W + (M + 1)/(M * N) * B, 
            R_hat = sqrt(V_hat / W))  
  
```
Y verificamos que los valores de $\hat{R}$ son cercanos a uno, lo
cual indica que este diagnóstico es aceptable. Si hubiéramos
trabajado con las primeras 300 iteraciones

```{r}
sims_tbl %>% 
  filter(iter_num < 300) %>% 
  pivot_longer(mu:sigma, names_to = "parametro", values_to = "valor") %>% 
  group_by(parametro, cadena) %>% 
  summarise(media = mean(valor), num = n(), sigma2 = var(valor)) %>% 
  summarise(N = first(num),
            M = n_distinct(cadena), 
            B = N * var(media),
            W = mean(sigma2),
            V_hat = ((N - 1) / N) * W + (M + 1)/(M * N) * B, 
            R_hat = sqrt(V_hat / W))  
  
```
Y estos valores indican problemas en la convergencia de las cadenas. Es
necesario diagnosticar el problema, que en este caso resolvemos
incrementando el número de iteraciones.


### Precisión {-}

Una vez que tenemos una muestra representativa de la 
distribución posterior, nuestro objetivo es asegurarnos de que la muestra es lo suficientemente grande 
para producir estimaciones estables y precisas de la distribución.

Para ello usaremos el 
**tamaño efectivo de muestra**, Si las simulaciones fueran independientes 
$N_{eff}$ sería el número total de simulaciones; sin embargo, las simulaciones de MCMC suelen estar correlacionadas, de modo que cada iteración 
de MCMC es menos informativa que si fueran independientes.

**Ejemplo**: Si graficaramos simulaciones independientes, esperaríamos valores de 
autocorrelación chicos:

```{r}
acf(rgamma(1000,1,1))
```
Sin embargo, los valores que simulamos tienen el siguiente perfil de
autocorrelación:

```{r}
sigma_metro_sims <- sims_tbl %>% filter(cadena==4) %>% pull(mu)
acf(sigma_metro_sims)
```

El tamaño efectivo de muestra nos dice qué tamaño de 
muestra de observaciones independientes nos daría la misma información que las
simulaciones de la cadena. Una manera de manera relativamente simple de 
estimarlo es:

$$N_{eff} = \frac{N}{1+2\sum_{k=1}^\infty ACF(k)} $$

Usualmente nos gustaría obtener un tamaño efectivo de al menos $100$ (para
cálculo de medias y varianzas posteriores). Esta
cantidad usualmente se reporta en el software (con mejores estimaciones que
la de la fórmula de arriba), y es necesario checarlo. 

En nuestro ejemplo hacemos una aproximación como sigue:

```{r}
calc_acf <- function(x){
  valores_acf <- acf(x, lag.max = 1000, plot = FALSE)$acf %>% as.numeric()
  valores_acf[-1]
}
acf_tbl <- sims_tbl %>% 
  pivot_longer(mu:sigma, "parametro", values_to = "valor") %>%
  group_by(parametro, cadena) %>%
  summarise(N = n_distinct(iter_num), k = 1:1000, acf = calc_acf(valor)) %>% 
  summarise(N = first(N), N_eff = N / (1 + 2 * sum(acf)))
acf_tbl
```

Nótese que algunas cadenas tienen un tamaño efectivo de muestra relativamente
bajo para el número de iteraciones que hicimos. De cualquier forma, el agregado
sobre todas las cadenas es suficientemente grande para calcular resúmenes básicos:

```{r}
acf_tbl %>% group_by(parametro) %>% 
  summarise(N = sum(N), N_eff = sum(N_eff))
```
Sin embargo, podemos hacer más simulaciones si es necesario, por ejemplo
para aproximar de manera apropiada percentiles en las colas.




### Eficiencia {-}

Hay varias maneras para mejorar la eficiencia de un proceso MCMC:


* Paralelizar, no disminuimos el número de pasos en las simulaciones pero 
podemos disminuir el tiempo que tarda en correr.

* Cambiar la parametrización del modelo o transformar los datos. 

* Adelgazar la muestra cuando tenemos problemas de uso de memoria,

consiste en guardar únicamente los $k$-ésimos pasos de la cadena y resulta
en cadenas con menos autocorrelación .

### Recomendaciones generales {-}

@gelman-hill recomienda los siguientes pasos cuando uno esta simulando de la
posterior:

1. Cuando definimos un modelo por primera vez establecemos un valor bajo para
el número de iteraciones. La razón es que la mayor parte de las veces los 
modelos no funcionan a la primera por lo que sería pérdida de tiempo dejarlo 
correr mucho tiempo antes de descubrir el problema.

2. Si las simulaciones no han alcanzado convergencia aumentamos las iteraciones 
a $500$ ó $1000$ de tal forma que las corridas tarden segundos o unos cuantos 
minutos.

3. Si tarda más que unos cuantos minutos (para problemas del tamaño que 
veremos en la clase) y aún así no alcanza convergencia 
entonces _juega_ un poco con el modelo (por ejemplo intenta transformaciones lineales), para JAGS Gelman 
sugiere más técnicas para acelerar la convergencia en el 
capitulo $19$ del libro 
*Data Analysis Using Regression and Multilevel/Hierarchical models*. En el 
caso de Stan veremos ejemplos de reparametrización, y se puede leer más en 
la [guía](https://mc-stan.org/docs/2_21/stan-users-guide/reparameterization-section.html).

4. Otra técnica conveniente cuando se trabaja con bases de datos grandes 
(sobre todo en la parte exploratoria) es trabajar con un 
subconjunto de los  datos, quizá la mitad o una quinta parte.

